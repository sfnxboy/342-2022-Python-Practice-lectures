{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7 - Python Lab\n",
    "## Author: *your name here*\n",
    "## Due: Check GitHub\n",
    "\n",
    "Students doing this lab in R will have an additional section where they practice speeding up R code using C++ via the `Rcpp` package. As of now, the practice notes (18) has not been created in Python, so we will skip this section for this lab.\n",
    "\n",
    "## Data Wrangling / Munging / Carpentry\n",
    "\n",
    "Throughout this assignment use Python's `Pandas` library. Keep the [Pandas Documentation](https://pandas.pydata.org/docs/) handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the `storms` dataset and investigate it using the `.info()`, `.describe()` and `.value_count()` functions.\n",
    "\n",
    "You can read up on the documentation for the dataset [here](https://vincentarelbundock.github.io/Rdatasets/doc/dplyr/storms.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for storms data\n",
    "url = \"https://raw.githubusercontent.com/sfnxboy/342-2022-Python-Practice-lectures/main/Datasets/storms.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Reorder the columns so name is first, status is second, category is third and the rest are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find a subset of the data of storms only in the 1970's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find a subset of the data of storm observations only with category 4 and above and wind speed 100MPH and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a new feature `wind_speed_per_unit_pressure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a new feature: `average_diameter` which averages the two diameter metrics. If one is missing, then use the value of the one that is present. If both are missing, leave missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. For each storm, summarize the maximum wind speed. \"Summarize\" means create a new dataframe with only the summary metrics you care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Order your dataset by maximum wind speed storm but within the rows of storm show the observations in time order from early to late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Find the strongest storm by wind speed per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. For each named storm, find its maximum category, wind speed, pressure and diameters. Do not allow the max to be NA (unless all the measurements for that storm were NA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. For each year in the dataset, tally the number of storms. \"Tally\" is a fancy word for \"count the number of\". Plot the number of storms by year. Any pattern?\n",
    "\n",
    "Hint: Use the `.groupby()` function. [Link to documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html?highlight=groupby#pandas.DataFrame.groupby)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. For each year in the dataset, tally the storms by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. For each year in the dataset, find the maximum wind speed per status level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. For each storm, summarize its average location in latitude / longitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. For each storm, summarize its duration in number of hours (to the nearest 6hr increment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. For storm in a category, create a variable `storm_number` that enumerates the storms 1, 2, ... (in date order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Convert year, month, day, hour into the variable `timestamp` using the `datetime` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Using the `datetime` package, create new variables `day_of_week` which is a factor with levels \"Sunday\", \"Monday\", ... \"Saturday\" and `week_of_year` which is integer 1, 2, ..., 52."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. For each storm, summarize the day in which is started in the following format \"Friday, June 27, 1975\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Create a new factor variable `decile_windspeed` by binning wind speed into 10 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Create a new data frame `serious_storms` which are category 3 and above hurricanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. In `serious_storms`, merge the variables lat and long together into `lat_long` with values `lat , long` as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Let's return now to the original storms data frame. For each category, find the average wind speed, pressure and diameters (do not count the NA's in your averaging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. For each named storm, find its maximum category, wind speed, pressure and diameters (do not allow the max to be NA) and the number of readings (i.e. observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Calculate the distance from each storm observation to Miami in a new variable `distance_to_miami`. This is very challenging. You will need a function that computes distances from two sets of latitude / longitude coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIAMI_LAT_LONG_COORDS = [25.7617, -80.1918]\n",
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. For each storm observation, use the function from the previous question to calculate the distance it moved since the previous observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. For each storm, find the total distance it moved over its observations and its total displacement. \"Distance\" is a scalar quantity that refers to \"how much ground an object has covered\" during its motion. \"Displacement\" is a vector quantity that refers to \"how far out of place an object is\"; it is the object's overall change in position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. For each storm observation, calculate the average speed the storm moved in location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. For each storm, calculate its average ground speed (how fast its eye is moving which is different from windspeed around the eye)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. Is there a relationship between average ground speed and maximum category attained? Use a dataframe summary (not a regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. Now we want to transition to building real design matrices for prediction. This is more in tune with what happens in the real world. Large data dump and you convert it into $X$ and $y$ how you see fit.\n",
    "\n",
    "Suppose we wish to predict the following: given the first three readings of a storm, can you predict its maximum wind speed? Identify the `y` and identify which features you need $x_1, ... x_p$ and build that dataframe with `Pandas` functions. This is not easy, but it is what it's all about. Feel free to \"featurize\" as creatively as you would like. You aren't going to overfit if you only build a few features relative to the total 198 storms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. Fit your model. Validate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. Assess your level of success at this endeavor.\n",
    "\n",
    "#TO-DO\n",
    "\n",
    "## The Forward Stepwise Procedure for Probability Estimation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34. Set a seed and load the `adult` dataset and remove missingness and randomize the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for storms data\n",
    "url = \"https://raw.githubusercontent.com/sfnxboy/342-2022-Python-Practice-lectures/main/Datasets/ucidata_adult.csv\"\n",
    "df = pd.read_csv(url, error_bad_lines=False)\n",
    "\n",
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. Copy from the previous lab all cleanups you did to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36. We will be doing model selection. We will split the dataset into 3 distinct subsets. Set the size of our splits here. For simplicitiy, all three splits will be identically sized. We are making it small so the stepwise algorithm can compute quickly. If you have a faster machine, feel free to increase this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsplitsize = 1000\n",
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37. Now create the following variables: `Xtrain`, `ytrain`, `Xselect`, `yselect`, `Xtest`, `ytest` with `Nsplitsize` observations. Make sure you've binarized the y values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38. Fit a vanilla logistic regression on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39. and report the log scoring rule, the Brier scoring rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be doing model selection using a basis of linear features consisting of all first-order interactions of the 14 raw features (this will include square terms as squares are interactions with oneself). \n",
    "\n",
    "40. Create a model matrix from the training data containing all these features. Make sure it has an intercept column too (the one vector is usually an important feature). Cast it as a data frame so we can use it more easily for modeling later on. We're going to need those model matrices (as data frames) for both the select and test sets. So make them here too (copy-paste). Make sure their dimensions are sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41. Write code that will fit a model stepwise. You can refer to the chunk in the practice lecture. Use the negative Brier score to do the selection. The negative of the Brier score is always positive and lower means better making this metric kind of like s_e so the picture will be the same as the canonical U-shape for oos performance. \n",
    "\n",
    "Run the code and interrupt the kernel when you begin to the see the Brier score degrade appreciably oos. Be patient as it will wobble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42. Plot the in-sample and oos (select set) Brier score by $p$. Does this look like what's expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
