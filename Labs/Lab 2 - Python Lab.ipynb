{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Python Lab\n",
    "## Author: *your name here*\n",
    "## Due: Check GitHub\n",
    "\n",
    "#### More Basic Python Skills\n",
    "\n",
    "1. Create a function `my_reverse` which takes as required input a vector `v` and returns the vector in reverse where the first entry is the last entry, etc. No function calls are allowed inside your function otherwise that would defeat the purpose of the exercise! (Yes, there is a base R function that does this called `rev`). Use `head` on `v` and `tail` on `my_reverse(v)` to verify it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function `flip_matrix` which takes as required input a matrix, an argument `dim_to_rev` that returns the matrix with the rows in reverse order or the columns in reverse order depending on the `dim_to_rev` argument. Let the default be the dimension of the matrix that is greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a list named `my_list` with keys \"A\", \"B\", ... where the entries are lists of size 1, 2 x 2, 3 x 3 x 3, etc. Fill the array with the numbers 1, 2, 3, etc. Make 8 entries according to this sequence. Be sure to import numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code\n",
    "my_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use `help(np.matrix.shape)` to read about what these functions do. Then explain the output you see above. For the later arrays, does it make sense given the dimensions of the arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\n",
    "\n",
    "\\# *TO-DO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Try to intelligently store this data. Use the data structure you think is suitable for this data.\n",
    "\n",
    "* M / Boomer: \"Theodore, Bernard, Gene, Herbert, Ray, Tom, Lee, Alfred, Leroy, Eddie\"\n",
    "* M / GenX: \"Marc, Jamie, Greg, Darryl, Tim, Dean, Jon, Chris, Troy, Jeff\"\n",
    "* M / Millennial: \"Zachary, Dylan, Christian, Wesley, Seth, Austin, Gabriel, Evan, Casey, Luis\"\n",
    "* F / Boomer: \"Gloria, Joan, Dorothy, Shirley, Betty, Dianne, Kay, Marjorie, Lorraine, Mildred\"\n",
    "* F / GenX: \"Tracy, Dawn, Tina, Tammy, Melinda, Tamara, Tracey, Colleen, Sherri, Heidi\"\n",
    "* F / Millennial: \"Samantha, Alexis, Brittany, Lauren, Taylor, Bethany, Latoya, Candice, Brittney, Cheyenne\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Imagine you are running an experiment with many manipulations. You have 14 levels in the variable \"treatment\" with levels a, b, c, etc. For each of those manipulations you have 3 submanipulations in a variable named \"variation\" with levels A, B, C. Then you have \"gender\" with levels M / F. Then you have \"generation\" with levels Boomer, GenX, Millenial. Then you will have 6 runs per each of these groups. In each set of 6 you will need to select a name without duplication from the appropriate set of names (from the last question). Create a data frame with columns treatment, variation, gender, generation, name and y that will store all the unique unit information in this experiment. Leave y empty because it will be measured as the experiment is executed.\n",
    "\n",
    "First, create this dataset as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 14 * 3 * 2 * 3 * 10\n",
    "\n",
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Convert the dictionary above into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Classification using KNN\n",
    "\n",
    "8. Write a k = 1 nearest neighbor algorithm using the Euclidean distance function. The following comments are standard \"Roxygen\" format for documentation. Hopefully, we will get to packages at some point and we will go over this again. It is your job also to fill in this documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_algorithm_predict(X_input, y_binary, X_test):\n",
    "    \"\"\"\n",
    "    Nearest Neighbors Algorithm\n",
    "    \n",
    "    X_input: *describe*\n",
    "    y_binary: *describe*\n",
    "    X_test: *describe*\n",
    "    \n",
    "    return: *describe*\n",
    "    \"\"\"\n",
    "    # TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a few tests to ensure it actually works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. We now add an argument `d` representing any legal distance function to the `nn_algorithm_predict` function. Update the implementation so it performs NN using that distance function. Set the default function to be the Euclidean distance in the original function. Also, alter the documentation in the appropriate places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Masters**\\\n",
    "11. For extra credit (unless you're a masters student), add an argument `k` to the `nn_algorithm_predict` function and update the implementation so it performs KNN. In the case of a tie, choose yhat randomly. Set the default `k` to be the square root of the size of D which is an empirical rule-of-thumb popularized by the \"Pattern Classification\" book by Duda, Hart and Stork (2007). Also, alter the documentation in the appropriate places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Binary Classification Modeling\n",
    "\n",
    "12. Load the famous `iris` data frame into the namespace. Provide a summary of the columns using the `head`, `.summary()` and `.describe()` functions and write a few descriptive sentences about the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Describe the data.\n",
    "\n",
    "\\# *TO-DO*\n",
    "\n",
    "14. The outcome / label / response is `Species`. This is what we will be trying to predict. However, we only care about binary classification between \"setosa\" and \"versicolor\" for the purposes of this exercise. Thus the first order of business is to drop one class. Let's drop the data for the level \"virginica\" from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Now create a vector `y` that is length the number of remaining rows in the data frame whose entries are 0 if \"setosa\" and 1 if \"versicolor\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Write a function `mode` returning the sample mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Fit a threshold model to `y` using the feature `Sepal.Length`. Write your own code to do this, preferably create a threshold function first. What is the estimated value of the threshold parameter? Save the threshold value as `threshold`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. What is the total number of errors this model makes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Summarize Sepal Length by the \"setosa\" and \"versicolor\" flowers. Hint: use the `groupby` Pandas function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Does the threshold model's performance make sense given the above summaries?\n",
    "\n",
    "*TO-DO*\n",
    "\n",
    "21. Create the function `g` explicitly that can predict `y` from `x` being a new `Sepal.Length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "22. You will code the \"perceptron learning algorithm\" for arbitrary number of features p. Take a look at the comments above the function. Respect the spec below, and edit the documentation to your understanding of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_learning_algorithm(X_input, y_binary, w, MAX_ITER = 1000):\n",
    "    \"\"\"\n",
    "    X_input: *describe*\n",
    "    y_binary: *describe*\n",
    "    w: *describe*\n",
    "    MAX_ITER: *describe*\n",
    "    \n",
    "    return: *describe*\n",
    "    \"\"\"\n",
    "    # TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what the algorithm is doing - linear \"discrimination\" between two response categories, we can draw a picture. First let's make up some very simple training data D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Xy_simple = pd.DataFrame({'response': [0, 0, 0, 1, 1, 1],\n",
    "                   'first_feature': [1, 1, 2, 3, 3, 4],\n",
    "                   'second_feature': [1, 2, 1, 3, 4, 3]})\n",
    "\n",
    "Xy_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't spoken about visualization yet, but it is important we do some of it now. Thus, I will write this code for you and you will just run it. First we load the visualization library we're going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the data using the Pandas plot() function\n",
    "Xy_simple.plot(x ='first_feature',\n",
    "                y='second_feature', \n",
    "                kind = 'scatter',\n",
    "                c = 'response',\n",
    "                cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Run the `perceptron_learning_algorithm` and explain the output. What do the numbers mean? What is the intercept of this line and the slope? You will have to do some algebra.\n",
    "\n",
    "*TO-DO*\n",
    "\n",
    "24. Plot the perceptron line on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Explain this picture. Why is this line of separation \"satisfying\" or not to you?\n",
    "\n",
    "*TO-DO*\n",
    "\n",
    "26. For extra credit, program the maximum-margin hyperplane perceptron that provides the best linear discrimination model for linearly separable data. Make sure you provide ROxygen documentation for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine vs. Perceptron\n",
    "\n",
    "We recreate the data from the previous lab and visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create df\n",
    "df = pd.DataFrame({'response': [0, 0, 0, 1, 1, 1],\n",
    "                   'first_feature': [1, 1, 2, 3, 3, 4],\n",
    "                   'second_feature': [1, 2, 1, 3, 4, 3]})\n",
    "\n",
    "# convert response to factor\n",
    "df['response'] = df['response'].astype('category')\n",
    "\n",
    "# snapshot\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize it\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scatter =plt.scatter(x =df['first_feature'],\n",
    "                     y=df['second_feature'], \n",
    "                     c = df['response'],\n",
    "                    )\n",
    "\n",
    "# Setting axis labels\n",
    "plt.xlabel('first_feature')\n",
    "plt.ylabel('second_feature')\n",
    "\n",
    "#add legend\n",
    "plt.legend(*scatter.legend_elements())\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. Use the `svm` package from the `sklearn` library to fit and SVM model to the simple data. Assign model to a variable named `clf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. (cont.) and then use the following code to visualize the line.\n",
    "\n",
    "(optional) First fit the svm model with a linear kernel, then do repeat the process again with the 'rbf' kernel. Observe the difference in the visualization below. Also tinker with the lambda value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Decision Region using mlxtend's awesome plotting function\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# plotting\n",
    "plot_decision_regions(X=X.values, \n",
    "                      y=y.values.astype(np.int_),\n",
    "                      clf=clf, \n",
    "                      legend=2)\n",
    "\n",
    "# Adding axes annotations\n",
    "plt.xlabel('first_feature')\n",
    "plt.ylabel('second_feature')\n",
    "plt.title('SVM - non-linearly seperable, lambda = 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. Now write pseuocode for your own implementation of the linear support vector machine algorithm using the Vapnik objective function we discussed.\n",
    "\n",
    "Note there are differences between this spec and the perceptron learning algorithm spec. You should figure out a way to respect the `MAX_ITER` argument value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svm_learning_algorithm(Xinput, y_binary, MAX_ITER = 5000, lambda_val = 0.1):\n",
    "    \"\"\"\n",
    "    Support Vector Machine\n",
    "    \n",
    "    This function implements the hinge-loss + maximum margin linear support vector\n",
    "    machine algorithm of Vladimir Vapnik (1963).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Xinput  :  The training data features as an n x p matrix.\n",
    "    y_binary  :  The training data responses as a vector of length n consisting of only 0's and 1's.\n",
    "    MAX_ITER  :  The maximum number of iterations the algorithm performs. Defaults to 5000.\n",
    "    lambda  :  A scalar hyperparameter trading off margin of the hyperplane versus average hinge loss.\n",
    "               The default value is 1.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    return  :  The computed final parameter (weight) as a vector of length p + 1\n",
    "    \"\"\"\n",
    "    # TO-DO\n",
    "    # Write pseudo-code as comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Masters**\\\n",
    "29. If you are enrolled in 342W the following is extra credit but if you're enrolled in a masters section, the following is required. Write the actual code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svm_learning_algorithm(Xinput, y_binary, MAX_ITER = 5000, lambda_val = 0.1):\n",
    "    \"\"\"\n",
    "    Support Vector Machine\n",
    "    \n",
    "    This function implements the hinge-loss + maximum margin linear support vector\n",
    "    machine algorithm of Vladimir Vapnik (1963).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Xinput  :  The training data features as an n x p matrix.\n",
    "    y_binary  :  The training data responses as a vector of length n consisting of only 0's and 1's.\n",
    "    MAX_ITER  :  The maximum number of iterations the algorithm performs. Defaults to 5000.\n",
    "    lambda  :  A scalar hyperparameter trading off margin of the hyperplane versus average hinge loss.\n",
    "               The default value is 1.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    return  :  The computed final parameter (weight) as a vector of length p + 1\n",
    "    \"\"\"\n",
    "    # TO-DO\n",
    "    # Complete the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wrote code above (the extra credit), run your function using the simple data, and use the default parameters. Be sure to plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this the same as what the `sklearn.svm` implementation returned? Why or why not?\n",
    "\n",
    "\\# *TO-DO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Classification using KNN\n",
    "\n",
    "30. Write a k = 1 nearest neighbor algorithm using the Euclidean distance function. It is your job also to fill in this documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_algorithm_predict (Xinput, y_binary, Xtest):\n",
    "    \"\"\"\n",
    "    # TO-DO (Provide a name for this function)\n",
    "    \n",
    "    # TO-DO (Explain what this function does in a few sentences)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Xinput  :  # TO-DO\n",
    "    y_binary  :  # TO-DO\n",
    "    Xtest  :  # TO-DO\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    return  :  # TO-DO\n",
    "    \"\"\"\n",
    "    # TO-DO\n",
    "    # Complete the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. Write a few tests to ensure it actually works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. We now add an argument `d` representing any legal distance function to the `nn_algorithm_predict` function. Update the implementation so it performs NN using that distance function. Set the default function to be the Euclidean distance in the original function. Also, alter the documentation in the appropriate places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Masters**\\\n",
    "33. For extra credit (unless you're a masters student), add an argument `k` to the `nn_algorithm_predict` function and update the implementation so it performs KNN. In the case of a tie, choose yhat randomly. Set the default `k` to be the square root of the size of D which is an empirical rule-of-thumb popularized by the \"Pattern Classification\" book by Duda, Hart and Stork (2007). Also, alter the documentation in the appropriate places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
