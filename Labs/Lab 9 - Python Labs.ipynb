{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52740d99",
   "metadata": {},
   "source": [
    "# Lab 9 - Python Lab\n",
    "## Author: *your name here*\n",
    "## Date: 11:59PM April XX, 2022\n",
    "\n",
    "Here we will learn about trees, bagged trees and random forests. You can use the `sklearn` package.\n",
    "\n",
    "Let's take a look at the simulated sine curve data from practice lecture 12. Below is the code for the data generating process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdea942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies you may need\n",
    "import numpy as np\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff06e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating mock dataset\n",
    "n = 500\n",
    "xmin = 0\n",
    "xmax = 10\n",
    "sigma = 0.3\n",
    "x_train = np.arange(start = xmin, stop = xmax, step = xmax/n)\n",
    "y_train = np.sin(X) + np.random.normal(0, sigma, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb5306",
   "metadata": {},
   "source": [
    "1. Plot an example dataset of size 500:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a8783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8101ce",
   "metadata": {},
   "source": [
    "2. Create a test set of size 500 as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e09131",
   "metadata": {},
   "source": [
    "3. Locate the optimal node size hyperparameter for the regression tree model. This might take some trial and error. Find the model with the optimal nodesize by s_e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b048f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0541c",
   "metadata": {},
   "source": [
    "4. Plot the regression tree model g(x) with the optimal node size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fbb6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56210ea",
   "metadata": {},
   "source": [
    "5. Provide the bias-variance decomposition of this DGP fit with this model. It is a lot of code, but it is in the practice lectures. If your three numbers don't add up within two significant digits, increase your resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f053498",
   "metadata": {},
   "source": [
    "6. Take a sample of n = 2000 observations from the diamonds data. You can find the .csv in the datasets folder of the 342 Python repository [here](https://github.com/sfnxboy/342-2022-Python-Practice-lectures). If you select to see the data in raw format on Github, you can use that URl as a parameter in the `pd.read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705daf4",
   "metadata": {},
   "source": [
    "7. Find the bootstrap s_e for a RF model using 1, 2, 5, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000 trees. If you are using the `randomForest` package, you can calculate oob residuals via `e_oob = y_train - yhat_oob`. Plot all models on a single graph, as well as the sampled data points. Make each model a unique color, and apply a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a41742",
   "metadata": {},
   "source": [
    "8. Using the diamonds data, find the oob s_e for a bagged-tree model using 1, 2, 5, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000 trees. If you are using the `randomForest` package, you can create the bagged tree model via setting an argument within the RF constructor function. Plot all models, again use best practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073dbdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354d2f0",
   "metadata": {},
   "source": [
    "9. What is the percentage gain / loss in performance of the RF model vs bagged trees model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20088ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87888ff",
   "metadata": {},
   "source": [
    "10. Plot oob s_e by number of trees for both RF and bagged trees using a long dataframe. Check Pandas documetation if you need a regresher on long dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a646d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeca895",
   "metadata": {},
   "source": [
    "11. Build RF models for 500 trees using different `max_features` (`mtry` in R) values: 1, 2, ... the maximum. Calculate oob s_e for all `max_features` values.\n",
    "\n",
    "According to the documentation, `max_features` defines the number of features to consider when looking for the best split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fe006",
   "metadata": {},
   "source": [
    "12. Plot oob s_e by max_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8762ef",
   "metadata": {},
   "source": [
    "13. Take a sample of n = 2000 observations from the adult data. You can find the .csv in the datasets folder of the 342 Python repository [here](https://github.com/sfnxboy/342-2022-Python-Practice-lectures). If you select to see the data in raw format on Github, you can use that URl as a parameter in the `pd.read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afba524",
   "metadata": {},
   "source": [
    "14. Using the adult data, find the bootstrap misclassification error for a RF model using 1, 2, 5, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0dd9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cabe2d",
   "metadata": {},
   "source": [
    "15. Using the adult data, find the bootstrap misclassification error for a bagged-tree model using 1, 2, 5, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000 trees. Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6887c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e1675",
   "metadata": {},
   "source": [
    "16. What is the percentage gain / loss in performance of the RF model vs bagged trees model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6bca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62636ab0",
   "metadata": {},
   "source": [
    "17. Plot bootstrap misclassification error by number of trees for both RF and bagged trees using a long data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf9998",
   "metadata": {},
   "source": [
    "18. Build RF models for 500 trees using different `max_features` (`mtry` in R) values: 1, 2, ... the maximum. Calculate oob s_e for all `max_features` values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bbf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6f0f2",
   "metadata": {},
   "source": [
    "19. Plot bootstrap misclassification error by `max_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d6745",
   "metadata": {},
   "source": [
    "20. Write a function `random_bagged_ols` which takes as its arguments `X` and `y` with further arguments `num_ols_models` defaulted to 100 and `max_features` defaulted to `auto`. This argument builds an OLS on a bootstrap sample of the data and uses only `mtry < p` of the available features. You can't store RF objects to any data structure in Python as far as I'm aware, so pickle the models to a local file. If you need help with pickling the models refer to the practice notes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56327a8",
   "metadata": {},
   "source": [
    "21. Load up the Boston Housing Data and separate into `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd76569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5fdc0e",
   "metadata": {},
   "source": [
    "22. Similar to lab 1, write a function that takes a matrix and punches holes (i.e. sets entries equal to `NA`) randomly with an argument `prob_missing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e76b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e29ac8",
   "metadata": {},
   "source": [
    "23. Create a matrix `Xmiss` which is `X` but has missingness with probability of 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e786a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ec679",
   "metadata": {},
   "source": [
    "24. Use a random forest modeling procedure to iteratively fill in the `NA`'s by predicting each feature of X using every other feature of X. You need to start by filling in the holes to use RF. So fill them in with the average of the feature. Don't use the `missingpy` package for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c111590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
